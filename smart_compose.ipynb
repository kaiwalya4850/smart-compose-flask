{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "smart_compose.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ziTjVYRw2Cse",
        "outputId": "abe7bbc4-1fc4-4a2f-a454-b489b33e771b"
      },
      "source": [
        "!pip install tensorflow-gpu==1.13.1"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow-gpu==1.13.1 in /usr/local/lib/python3.6/dist-packages (1.13.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.13.1) (1.1.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.13.1) (0.8.1)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.13.1) (0.3.3)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.13.1) (1.1.2)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.13.1) (1.0.8)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.13.1) (1.19.4)\n",
            "Requirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.13.1) (0.10.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.13.1) (3.12.4)\n",
            "Requirement already satisfied: tensorflow-estimator<1.14.0rc0,>=1.13.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.13.1) (1.13.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.13.1) (0.36.2)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.13.1) (1.32.0)\n",
            "Requirement already satisfied: tensorboard<1.14.0,>=1.13.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.13.1) (1.13.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.13.1) (1.15.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow-gpu==1.13.1) (2.10.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow-gpu==1.13.1) (51.0.0)\n",
            "Requirement already satisfied: mock>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-estimator<1.14.0rc0,>=1.13.0->tensorflow-gpu==1.13.1) (4.0.3)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow-gpu==1.13.1) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow-gpu==1.13.1) (3.3.3)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<1.14.0,>=1.13.0->tensorflow-gpu==1.13.1) (3.3.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.14.0,>=1.13.0->tensorflow-gpu==1.13.1) (3.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.14.0,>=1.13.0->tensorflow-gpu==1.13.1) (3.7.4.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "CIefsTKD2Lvm",
        "outputId": "854f1a4a-6a27-4580-cbac-8f050c389e4c"
      },
      "source": [
        "%matplotlib inline\r\n",
        "%tensorflow_version 1.x\r\n",
        "import tensorflow as tf\r\n",
        "from tensorflow import keras\r\n",
        "from tensorflow.keras.models import Model\r\n",
        "from tensorflow.keras.layers import Input, LSTM, Dense, Embedding, CuDNNLSTM, Flatten, TimeDistributed, Dropout, LSTMCell, RNN, Bidirectional, Concatenate, Layer\r\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\r\n",
        "from tensorflow.python.keras.utils import tf_utils\r\n",
        "from tensorflow.keras import backend as K\r\n",
        "\r\n",
        "import unicodedata\r\n",
        "import re\r\n",
        "import numpy as np\r\n",
        "import os\r\n",
        "import time\r\n",
        "import shutil\r\n",
        "\r\n",
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "import string, os \r\n",
        "tf.__version__"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'1.15.2'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vQNNqiXBo8ao",
        "outputId": "cbaba4d3-3b8e-4d34-97a3-205d70da50f4"
      },
      "source": [
        "from google.colab import drive\r\n",
        "import os\r\n",
        "drive.mount('/content/drive',force_remount=True)\r\n",
        "os.chdir(\"/content/drive/My Drive/Colab Notebooks\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 360
        },
        "id": "VG6sBlXqqUq0",
        "outputId": "9ee26e84-6337-43f2-efca-1cd05e9016e5"
      },
      "source": [
        "import pandas as pd\r\n",
        "data = pd.read_csv(\"emails.csv\")     # Download and extract dataset from: https://www.kaggle.com/wcukierski/enron-email-dataset\r\n",
        "pd.set_option('display.max_colwidth',-1)\r\n",
        "new = data[\"message\"].str.split(\"\\n\", n = 15, expand = True) \r\n",
        "\r\n",
        "data[\"from\"] = new[2]\r\n",
        "data[\"fromn\"] = new[8]\r\n",
        "data[\"to\"] = new[3]\r\n",
        "data[\"ton\"] = new[9]\r\n",
        "data[\"subject\"] = new[4]\r\n",
        "data[\"msg\"] = new[15]\r\n",
        "data.drop(columns =[\"message\"], inplace = True) \r\n",
        "data.drop(columns =[\"file\"], inplace = True) \r\n",
        "\r\n",
        "data['from'] = data[\"from\"].apply(lambda val: val.replace(\"From:\",''))\r\n",
        "data['fromn'] = data[\"fromn\"].apply(lambda val: val.replace(\"X-From:\",''))\r\n",
        "data['to'] = data[\"to\"].apply(lambda val: val.replace(\"To:\",''))\r\n",
        "data['ton'] = data[\"ton\"].apply(lambda val: val.replace(\"X-To:\",''))\r\n",
        "data['subject'] = data[\"subject\"].apply(lambda val: val.replace(\"Subject:\",''))\r\n",
        "data['msg'] = data[\"msg\"].apply(lambda val: val.replace(\"\\n\",' '))\r\n",
        "\r\n",
        "# Lets look only at emails with 100 words or less and that are Non-replies\r\n",
        "data[(data['msg'].str.len() <100) & ~(data['subject'].str.contains('Re:'))].sample(5)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: FutureWarning: Passing a negative integer is deprecated in version 1.0 and will not be supported in future version. Instead, use None to not limit the column width.\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>from</th>\n",
              "      <th>fromn</th>\n",
              "      <th>to</th>\n",
              "      <th>ton</th>\n",
              "      <th>subject</th>\n",
              "      <th>msg</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>251845</th>\n",
              "      <td>maureen.mcvicker@enron.com</td>\n",
              "      <td>Maureen McVicker</td>\n",
              "      <td>brian.schaffer@enron.com</td>\n",
              "      <td>Brian Schaffer</td>\n",
              "      <td>memo</td>\n",
              "      <td>Please see the revised memo, which is the final version.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>180079</th>\n",
              "      <td>tana.jones@enron.com</td>\n",
              "      <td>Tana Jones</td>\n",
              "      <td>david.minns@enron.com</td>\n",
              "      <td>David Minns</td>\n",
              "      <td>Just a Note</td>\n",
              "      <td>We've got an Australian counterparty on the list for the 18th.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>218459</th>\n",
              "      <td>vince.kaminski@enron.com</td>\n",
              "      <td>Vince J Kaminski</td>\n",
              "      <td>vkaminski@aol.com</td>\n",
              "      <td>vkaminski@aol.com</td>\n",
              "      <td></td>\n",
              "      <td>http://www-path.eecs.berkeley.edu:80/~ucenergy/PDFDown.html</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>111719</th>\n",
              "      <td>mjones7@txu.com</td>\n",
              "      <td>Content-Type: text/plain; charset=us-ascii</td>\n",
              "      <td>daren.j.farmer@enron.com, ggreen2@txu.com, cstone1@txu.com,</td>\n",
              "      <td>Content-Transfer-Encoding: 7bit</td>\n",
              "      <td>\\tkenenglish@txu.com, timpowell@txu.com, gary.a.hanks@enron.com,</td>\n",
              "      <td>X-Origin: Farmer-D X-FileName: dfarmer.nsf  (See attached file: hpl0817.xls)   - hpl0817.xls</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>142651</th>\n",
              "      <td>jtp497@rcn.com</td>\n",
              "      <td>jtp497@rcn.com</td>\n",
              "      <td>john.griffith@enron.com</td>\n",
              "      <td>John Griffith &lt;john.griffith@enron.com&gt;</td>\n",
              "      <td>Book1.xls</td>\n",
              "      <td>- Book1.xls</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                               from  ...                                                                                           msg\n",
              "251845   maureen.mcvicker@enron.com  ...   Please see the revised memo, which is the final version.                                   \n",
              "180079   tana.jones@enron.com        ...   We've got an Australian counterparty on the list for the 18th.                             \n",
              "218459   vince.kaminski@enron.com    ...   http://www-path.eecs.berkeley.edu:80/~ucenergy/PDFDown.html                                \n",
              "111719   mjones7@txu.com             ...  X-Origin: Farmer-D X-FileName: dfarmer.nsf  (See attached file: hpl0817.xls)   - hpl0817.xls\n",
              "142651   jtp497@rcn.com              ...    - Book1.xls                                                                               \n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x60z1hfpzQGi",
        "outputId": "a3899550-c542-467a-fe73-2b24b6c1fcfc"
      },
      "source": [
        "data = data[(data['msg'].str.len() <75) & ~(data['subject'].str.contains('Re:'))]\r\n",
        "corpus = list(data['msg'])\r\n",
        "print(len(corpus))\r\n",
        "print(corpus[0:10])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "18181\n",
            "[' Here is our forecast   ', ' Greg,  Happy B-day. Email me your phone # and I will call you.  Keith', ' Jeff,   What is up with Burnet?  Phillip', ' http://www.hearme.com/vc2/?chnlOwnr=pallen@enron.com', ' Ina,   I scheduled a meeting with Jean Mrha tomorrow at 3:30', ' Brenda   Can you send me your address in College Station.  Phillip', ' Here is the 1st draft of a wish list for systems.  ', ' testing', ' http://ectpdx-sunone.ect.enron.com/~theizen/wsccnav/', ' Check out NP Gen & Load.  (aMW)']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qTyW4Q9I0HYs"
      },
      "source": [
        "def clean_special_chars(text, punct):\r\n",
        "    for p in punct:\r\n",
        "        text = text.replace(p, '')\r\n",
        "    return text\r\n",
        "\r\n",
        "      \r\n",
        "def preprocess(data):\r\n",
        "    output = []\r\n",
        "    punct = '#$%&*+-/<=>@[\\\\]^_`{|}~\\t\\n'\r\n",
        "    for line in data:\r\n",
        "         pline= clean_special_chars(line.lower(), punct)\r\n",
        "         output.append(pline)\r\n",
        "    return output  \r\n",
        "\r\n",
        "\r\n",
        "def generate_dataset():\r\n",
        "  \r\n",
        "    processed_corpus = preprocess(corpus)    \r\n",
        "    output = []\r\n",
        "    for line in processed_corpus:\r\n",
        "        token_list = line\r\n",
        "        for i in range(1, len(token_list)):\r\n",
        "            data = []\r\n",
        "            x_ngram = '<start> '+ token_list[:i+1] + ' <end>'\r\n",
        "            y_ngram = '<start> '+ token_list[i+1:] + ' <end>'\r\n",
        "            data.append(x_ngram)\r\n",
        "            data.append(y_ngram)\r\n",
        "            output.append(data)\r\n",
        "    print(\"Dataset prepared with prefix and suffixes for teacher forcing technique\")\r\n",
        "    dummy_df = pd.DataFrame(output, columns=['input','output'])\r\n",
        "    return output, dummy_df "
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N-VpxClm17Su"
      },
      "source": [
        "class LanguageIndex():\r\n",
        "    def __init__(self, lang):\r\n",
        "        self.lang = lang\r\n",
        "        self.word2idx = {}\r\n",
        "        self.idx2word = {}\r\n",
        "        self.vocab = set()\r\n",
        "        self.create_index()\r\n",
        "    def create_index(self):\r\n",
        "        for phrase in self.lang:\r\n",
        "            self.vocab.update(phrase.split(' '))\r\n",
        "        self.vocab = sorted(self.vocab)\r\n",
        "        self.word2idx[\"<pad>\"] = 0\r\n",
        "        self.idx2word[0] = \"<pad>\"\r\n",
        "        for i,word in enumerate(self.vocab):\r\n",
        "            self.word2idx[word] = i + 1\r\n",
        "            self.idx2word[i+1] = word\r\n",
        "\r\n",
        "def max_length(t):\r\n",
        "    return max(len(i) for i in t)\r\n",
        "\r\n",
        "def load_dataset():\r\n",
        "    pairs,df = generate_dataset()\r\n",
        "    out_lang = LanguageIndex(sp for en, sp in pairs)\r\n",
        "    in_lang = LanguageIndex(en for en, sp in pairs)\r\n",
        "    input_data = [[in_lang.word2idx[s] for s in en.split(' ')] for en, sp in pairs]\r\n",
        "    output_data = [[out_lang.word2idx[s] for s in sp.split(' ')] for en, sp in pairs]\r\n",
        "\r\n",
        "    max_length_in, max_length_out = max_length(input_data), max_length(output_data)\r\n",
        "    input_data = tf.keras.preprocessing.sequence.pad_sequences(input_data, maxlen=max_length_in, padding=\"post\")\r\n",
        "    output_data = tf.keras.preprocessing.sequence.pad_sequences(output_data, maxlen=max_length_out, padding=\"post\")\r\n",
        "    return input_data, output_data, in_lang, out_lang, max_length_in, max_length_out, df"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mK7jcPFX3Nt5",
        "outputId": "702be4ed-88d9-439c-8dcf-d4a04f3c7d30"
      },
      "source": [
        "input_data, teacher_data, input_lang, target_lang, len_input, len_target, df = load_dataset()\r\n",
        "\r\n",
        "\r\n",
        "target_data = [[teacher_data[n][i+1] for i in range(len(teacher_data[n])-1)] for n in range(len(teacher_data))]\r\n",
        "target_data = tf.keras.preprocessing.sequence.pad_sequences(target_data, maxlen=len_target, padding=\"post\")\r\n",
        "target_data = target_data.reshape((target_data.shape[0], target_data.shape[1], 1))\r\n",
        "\r\n",
        "# Shuffle all of the data in unison. This training set has the longest (e.g. most complicated) data at the end,\r\n",
        "# so a simple Keras validation split will be problematic if not shuffled.\r\n",
        "\r\n",
        "p = np.random.permutation(len(input_data))\r\n",
        "input_data = input_data[p]\r\n",
        "teacher_data = teacher_data[p]\r\n",
        "target_data = target_data[p]"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dataset prepared with prefix and suffixes for teacher forcing technique\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        },
        "id": "PDMo5LnX3TE1",
        "outputId": "9abeda56-1957-4237-b868-2498109655a5"
      },
      "source": [
        "pd.set_option('display.max_colwidth', -1)\r\n",
        "BUFFER_SIZE = len(input_data)\r\n",
        "BATCH_SIZE = 128\r\n",
        "embedding_dim = 300\r\n",
        "units = 128\r\n",
        "vocab_in_size = len(input_lang.word2idx)\r\n",
        "vocab_out_size = len(target_lang.word2idx)\r\n",
        "df.iloc[60:65]"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: FutureWarning: Passing a negative integer is deprecated in version 1.0 and will not be supported in future version. Instead, use None to not limit the column width.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>input</th>\n",
              "      <th>output</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>60</th>\n",
              "      <td>&lt;start&gt;  greg,  happy bday. email me your phone &lt;end&gt;</td>\n",
              "      <td>&lt;start&gt;   and i will call you.  keith &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61</th>\n",
              "      <td>&lt;start&gt;  greg,  happy bday. email me your phone  &lt;end&gt;</td>\n",
              "      <td>&lt;start&gt;  and i will call you.  keith &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62</th>\n",
              "      <td>&lt;start&gt;  greg,  happy bday. email me your phone   &lt;end&gt;</td>\n",
              "      <td>&lt;start&gt; and i will call you.  keith &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>63</th>\n",
              "      <td>&lt;start&gt;  greg,  happy bday. email me your phone  a &lt;end&gt;</td>\n",
              "      <td>&lt;start&gt; nd i will call you.  keith &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>64</th>\n",
              "      <td>&lt;start&gt;  greg,  happy bday. email me your phone  an &lt;end&gt;</td>\n",
              "      <td>&lt;start&gt; d i will call you.  keith &lt;end&gt;</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                        input                                       output\n",
              "60  <start>  greg,  happy bday. email me your phone <end>      <start>   and i will call you.  keith <end>\n",
              "61  <start>  greg,  happy bday. email me your phone  <end>     <start>  and i will call you.  keith <end> \n",
              "62  <start>  greg,  happy bday. email me your phone   <end>    <start> and i will call you.  keith <end>  \n",
              "63  <start>  greg,  happy bday. email me your phone  a <end>   <start> nd i will call you.  keith <end>   \n",
              "64  <start>  greg,  happy bday. email me your phone  an <end>  <start> d i will call you.  keith <end>    "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mnxQMCSp3x-O"
      },
      "source": [
        "from tensorflow.keras.layers import Input, LSTM, Dense, Embedding, CuDNNLSTM, Flatten, TimeDistributed, Dropout, LSTMCell, RNN, Bidirectional, Concatenate, Layer"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dyOhwn-z3ZHu",
        "outputId": "72e7e7c0-9131-4023-bb99-c85b720c6f8a"
      },
      "source": [
        "encoder_inputs = Input(shape=(len_input,))\r\n",
        "encoder_emb = Embedding(input_dim=vocab_in_size, output_dim=embedding_dim)\r\n",
        "\r\n",
        "# Use this if you dont need Bidirectional LSTM\r\n",
        "# encoder_lstm = CuDNNLSTM(units=units, return_sequences=True, return_state=True)\r\n",
        "# encoder_out, state_h, state_c = encoder_lstm(encoder_emb(encoder_inputs))\r\n",
        "\r\n",
        "encoder_lstm = Bidirectional(CuDNNLSTM(units=units, return_sequences=True, return_state=True))\r\n",
        "encoder_out, fstate_h, fstate_c, bstate_h, bstate_c = encoder_lstm(encoder_emb(encoder_inputs))\r\n",
        "state_h = Concatenate()([fstate_h,bstate_h])\r\n",
        "state_c = Concatenate()([bstate_h,bstate_c])\r\n",
        "encoder_states = [state_h, state_c]\r\n",
        "\r\n",
        "\r\n",
        "# Now create the Decoder layers.\r\n",
        "decoder_inputs = Input(shape=(None,))\r\n",
        "decoder_emb = Embedding(input_dim=vocab_out_size, output_dim=embedding_dim)\r\n",
        "decoder_lstm = CuDNNLSTM(units=units*2, return_sequences=True, return_state=True)\r\n",
        "decoder_lstm_out, _, _ = decoder_lstm(decoder_emb(decoder_inputs), initial_state=encoder_states)\r\n",
        "# Two dense layers added to this model to improve inference capabilities.\r\n",
        "decoder_d1 = Dense(units, activation=\"relu\")\r\n",
        "decoder_d2 = Dense(vocab_out_size, activation=\"softmax\")\r\n",
        "decoder_out = decoder_d2(Dropout(rate=.2)(decoder_d1(Dropout(rate=.2)(decoder_lstm_out))))\r\n",
        "\r\n",
        "\r\n",
        "# Finally, create a training model which combines the encoder and the decoder.\r\n",
        "# Note that this model has three inputs:\r\n",
        "model = Model(inputs = [encoder_inputs, decoder_inputs], outputs= decoder_out)\r\n",
        "\r\n",
        "# We'll use sparse_categorical_crossentropy so we don't have to expand decoder_out into a massive one-hot array.\r\n",
        "# Adam is used because it's, well, the best.\r\n",
        "\r\n",
        "model.compile(optimizer=tf.train.AdamOptimizer(), loss=\"sparse_categorical_crossentropy\", metrics=['sparse_categorical_accuracy'])\r\n",
        "model.summary()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/keras/initializers.py:119: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/init_ops.py:97: calling Orthogonal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 47)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 47, 300)      16986300    input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional (Bidirectional)   [(None, 47, 256), (N 440320      embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, None, 300)    19320600    input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 256)          0           bidirectional[0][1]              \n",
            "                                                                 bidirectional[0][3]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 256)          0           bidirectional[0][3]              \n",
            "                                                                 bidirectional[0][4]              \n",
            "__________________________________________________________________________________________________\n",
            "cu_dnnlstm_1 (CuDNNLSTM)        [(None, None, 256),  571392      embedding_1[0][0]                \n",
            "                                                                 concatenate[0][0]                \n",
            "                                                                 concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, None, 256)    0           cu_dnnlstm_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, None, 128)    32896       dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, None, 128)    0           dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, None, 64402)  8307858     dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 45,659,366\n",
            "Trainable params: 45,659,366\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "LDtmwv5G3dIW",
        "outputId": "c193f2c8-2222-482f-fceb-6df1fd6c8f53"
      },
      "source": [
        "epochs = 10\r\n",
        "history = model.fit([input_data, teacher_data], target_data,\r\n",
        "                 batch_size= BATCH_SIZE,\r\n",
        "                 epochs=epochs,\r\n",
        "                 validation_split=0.2)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Train on 596341 samples, validate on 149086 samples\n",
            "Epoch 1/10\n",
            "596341/596341 [==============================] - 3742s 6ms/sample - loss: 0.5911 - sparse_categorical_accuracy: 0.9156 - val_loss: 0.3179 - val_sparse_categorical_accuracy: 0.9469\n",
            "Epoch 2/10\n",
            " 30464/596341 [>.............................] - ETA: 53:22 - loss: 0.3369 - sparse_categorical_accuracy: 0.9420"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:root:Internal Python error in the inspect module.\n",
            "Below is the traceback from this internal error.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"<ipython-input-14-70b738719332>\", line 5, in <module>\n",
            "    validation_split=0.2)\n",
            "  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/python/keras/engine/training.py\", line 727, in fit\n",
            "    use_multiprocessing=use_multiprocessing)\n",
            "  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/python/keras/engine/training_arrays.py\", line 675, in fit\n",
            "    steps_name='steps_per_epoch')\n",
            "  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/python/keras/engine/training_arrays.py\", line 394, in model_iteration\n",
            "    batch_outs = f(ins_batch)\n",
            "  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/python/keras/backend.py\", line 3476, in __call__\n",
            "    run_metadata=self.run_metadata)\n",
            "  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/python/client/session.py\", line 1472, in __call__\n",
            "    run_metadata_ptr)\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 1823, in showtraceback\n",
            "    stb = value._render_traceback_()\n",
            "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/ultratb.py\", line 1132, in get_records\n",
            "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/ultratb.py\", line 313, in wrapped\n",
            "    return f(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/ultratb.py\", line 358, in _fixed_getinnerframes\n",
            "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
            "  File \"/usr/lib/python3.6/inspect.py\", line 1490, in getinnerframes\n",
            "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
            "  File \"/usr/lib/python3.6/inspect.py\", line 1448, in getframeinfo\n",
            "    filename = getsourcefile(frame) or getfile(frame)\n",
            "  File \"/usr/lib/python3.6/inspect.py\", line 696, in getsourcefile\n",
            "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
            "  File \"/usr/lib/python3.6/inspect.py\", line 733, in getmodule\n",
            "    if ismodule(module) and hasattr(module, '__file__'):\n",
            "  File \"/tensorflow-1.15.2/python3.6/tensorflow/__init__.py\", line 50, in __getattr__\n",
            "    module = self._load()\n",
            "  File \"/tensorflow-1.15.2/python3.6/tensorflow/__init__.py\", line 44, in _load\n",
            "    module = _importlib.import_module(self.__name__)\n",
            "  File \"/usr/lib/python3.6/importlib/__init__.py\", line 126, in import_module\n",
            "    return _bootstrap._gcd_import(name[level:], package, level)\n",
            "  File \"<frozen importlib._bootstrap>\", line 994, in _gcd_import\n",
            "  File \"<frozen importlib._bootstrap>\", line 971, in _find_and_load\n",
            "  File \"<frozen importlib._bootstrap>\", line 955, in _find_and_load_unlocked\n",
            "  File \"<frozen importlib._bootstrap>\", line 665, in _load_unlocked\n",
            "  File \"<frozen importlib._bootstrap_external>\", line 678, in exec_module\n",
            "  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n",
            "  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/contrib/__init__.py\", line 72, in <module>\n",
            "    from tensorflow.contrib import periodic_resample\n",
            "  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/contrib/periodic_resample/__init__.py\", line 22, in <module>\n",
            "    from tensorflow.contrib.periodic_resample.python.ops.periodic_resample_op import periodic_resample\n",
            "  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/contrib/periodic_resample/__init__.py\", line 22, in <module>\n",
            "    from tensorflow.contrib.periodic_resample.python.ops.periodic_resample_op import periodic_resample\n",
            "  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/contrib/periodic_resample/python/ops/periodic_resample_op.py\", line 32, in <module>\n",
            "    resource_loader.get_path_to_datafile('_periodic_resample_op.so'))\n",
            "  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/contrib/util/loader.py\", line 56, in load_op_library\n",
            "    ret = load_library.load_op_library(path)\n",
            "  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/python/framework/load_library.py\", line 61, in load_op_library\n",
            "    lib_handle = py_tf.TF_LoadLibrary(library_filename)\n",
            "KeyboardInterrupt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eazi8zm-8xM2"
      },
      "source": [
        "import matplotlib.pyplot as plt\r\n",
        "\r\n",
        "plt.plot(history.history['loss'], label=\"Training loss\")\r\n",
        "plt.plot(history.history['val_loss'], label=\"Validation loss\")\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yhaw1cKc87jV"
      },
      "source": [
        "# Create the encoder model from the tensors we previously declared.\r\n",
        "encoder_model = Model(encoder_inputs, [encoder_out, state_h, state_c])\r\n",
        "\r\n",
        "# Generate a new set of tensors for our new inference decoder. Note that we are using new tensors, \r\n",
        "# this does not preclude using the same underlying layers that we trained on. (e.g. weights/biases).\r\n",
        "\r\n",
        "inf_decoder_inputs = Input(shape=(None,), name=\"inf_decoder_inputs\")\r\n",
        "# We'll need to force feed the two state variables into the decoder each step.\r\n",
        "state_input_h = Input(shape=(units*2,), name=\"state_input_h\")\r\n",
        "state_input_c = Input(shape=(units*2,), name=\"state_input_c\")\r\n",
        "decoder_res, decoder_h, decoder_c = decoder_lstm(\r\n",
        "    decoder_emb(inf_decoder_inputs), \r\n",
        "    initial_state=[state_input_h, state_input_c])\r\n",
        "inf_decoder_out = decoder_d2(decoder_d1(decoder_res))\r\n",
        "inf_model = Model(inputs=[inf_decoder_inputs, state_input_h, state_input_c], \r\n",
        "                  outputs=[inf_decoder_out, decoder_h, decoder_c])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2qBmKblc8-ll"
      },
      "source": [
        "def sentence_to_vector(sentence, lang):\r\n",
        "\r\n",
        "    pre = sentence\r\n",
        "    vec = np.zeros(len_input)\r\n",
        "    sentence_list = [lang.word2idx[s] for s in pre.split(' ')]\r\n",
        "    for i,w in enumerate(sentence_list):\r\n",
        "        vec[i] = w\r\n",
        "    return vec\r\n",
        "\r\n",
        "# Given an input string, an encoder model (infenc_model) and a decoder model (infmodel),\r\n",
        "def translate(input_sentence, infenc_model, infmodel):\r\n",
        "    sv = sentence_to_vector(input_sentence, input_lang)\r\n",
        "    sv = sv.reshape(1,len(sv))\r\n",
        "    [emb_out, sh, sc] = infenc_model.predict(x=sv)\r\n",
        "    \r\n",
        "    i = 0\r\n",
        "    start_vec = target_lang.word2idx[\"<start>\"]\r\n",
        "    stop_vec = target_lang.word2idx[\"<end>\"]\r\n",
        "    \r\n",
        "    cur_vec = np.zeros((1,1))\r\n",
        "    cur_vec[0,0] = start_vec\r\n",
        "    cur_word = \"<start>\"\r\n",
        "    output_sentence = \"\"\r\n",
        "\r\n",
        "    while cur_word != \"<end>\" and i < (len_target-1):\r\n",
        "        i += 1\r\n",
        "        if cur_word != \"<start>\":\r\n",
        "            output_sentence = output_sentence + \" \" + cur_word\r\n",
        "        x_in = [cur_vec, sh, sc]\r\n",
        "        [nvec, sh, sc] = infmodel.predict(x=x_in)\r\n",
        "        cur_vec[0,0] = np.argmax(nvec[0,0])\r\n",
        "        cur_word = target_lang.idx2word[np.argmax(nvec[0,0])]\r\n",
        "    return output_sentence"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d6RAbUYL9HH6"
      },
      "source": [
        "test = [\r\n",
        "    'hi there',\r\n",
        "    'hell',\r\n",
        "    'presentation please fin',\r\n",
        "    'resignation please find at',\r\n",
        "    'resignation please ',\r\n",
        "    'have a nice we',\r\n",
        "    'let me ',\r\n",
        "    'promotion congrats ',\r\n",
        "    'christmas Merry ',\r\n",
        "    'please rev',\r\n",
        "    'please ca',\r\n",
        "    'thanks fo',\r\n",
        "    'Let me kno',\r\n",
        "    'Let me know if y',\r\n",
        "    'this soun',\r\n",
        "    'is this call going t'\r\n",
        "]\r\n",
        "  \r\n",
        "\r\n",
        "import pandas as pd\r\n",
        "output = []  \r\n",
        "for t in test:  \r\n",
        "  output.append({\"Input seq\":t.lower(), \"Pred. Seq\":translate(t.lower(), encoder_model, inf_model)})\r\n",
        "\r\n",
        "results_df = pd.DataFrame.from_dict(output) \r\n",
        "results_df.head(len(test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mR8kum69Ez9i"
      },
      "source": [
        "# This is to save the model for the web app to use for generation\r\n",
        "from keras.models import model_from_json\r\n",
        "from keras.models import load_model\r\n",
        "\r\n",
        "# serialize model to JSON\r\n",
        "#  the keras model which is trained is defined as 'model' in this example\r\n",
        "model_json = inf_model.to_json()\r\n",
        "\r\n",
        "\r\n",
        "with open(\"model_num.json\", \"w\") as json_file:\r\n",
        "    json_file.write(model_json)\r\n",
        "\r\n",
        "# serialize weights to HDF5\r\n",
        "inf_model.save_weights(\"model_inf.h5\")\r\n",
        "encoder_model.save_weights(\"model_enc.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3P1JH_QdHmuu"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}